"""å»ºç«‹å€ªæµ·å»ˆçŸ¥è­˜åº« - è™•ç† PDFã€å½±ç‰‡ã€æ–‡å­—ä¸¦å»ºç«‹å‘é‡è³‡æ–™åº«."""
import os
from pathlib import Path
from typing import List, Dict
import json

# æ–‡ä»¶è™•ç†
import pdfplumber
from docx import Document

# å‘é‡è³‡æ–™åº«
import chromadb
from chromadb.utils import embedding_functions

# è¨­å®š
PROJECT_ROOT = Path(__file__).parent.parent
KNOWLEDGE_RAW = PROJECT_ROOT / "knowledge" / "raw"
KNOWLEDGE_PROCESSED = PROJECT_ROOT / "knowledge" / "processed"
CHROMA_DB_PATH = KNOWLEDGE_PROCESSED / "chroma_db"


def extract_text_from_pdf(pdf_path: Path) -> str:
    """å¾ PDF æå–æ–‡å­—."""
    print(f"  ğŸ“„ è™•ç† PDF: {pdf_path.name}")
    text = ""
    try:
        with pdfplumber.open(pdf_path) as pdf:
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    text += page_text + "\n\n"
    except Exception as e:
        print(f"    âŒ éŒ¯èª¤: {e}")
    return text


def extract_text_from_docx(docx_path: Path) -> str:
    """å¾ Word æ–‡ä»¶æå–æ–‡å­—."""
    print(f"  ğŸ“ è™•ç† DOCX: {docx_path.name}")
    try:
        doc = Document(docx_path)
        text = "\n\n".join([para.text for para in doc.paragraphs if para.text.strip()])
        return text
    except Exception as e:
        print(f"    âŒ éŒ¯èª¤: {e}")
        return ""


def extract_text_from_txt(txt_path: Path) -> str:
    """è®€å–ç´”æ–‡å­—æª”."""
    print(f"  ğŸ“ƒ è™•ç† TXT: {txt_path.name}")
    try:
        with open(txt_path, 'r', encoding='utf-8') as f:
            return f.read()
    except Exception as e:
        print(f"    âŒ éŒ¯èª¤: {e}")
        return ""


def transcribe_video(video_path: Path) -> str:
    """å°‡å½±ç‰‡/éŸ³è¨Šè½‰æˆæ–‡å­—ï¼ˆä½¿ç”¨ Whisperï¼‰."""
    print(f"  ğŸ¬ è½‰éŒ„å½±ç‰‡: {video_path.name}")
    try:
        import whisper
        model = whisper.load_model("base")  # å¯æ”¹ small, medium, large
        result = model.transcribe(str(video_path), language="zh")
        return result["text"]
    except ImportError:
        print("    âš ï¸ è«‹å®‰è£ whisper: pip install openai-whisper")
        return ""
    except Exception as e:
        print(f"    âŒ éŒ¯èª¤: {e}")
        return ""


def chunk_text(text: str, chunk_size: int = 1000, overlap: int = 200) -> List[str]:
    """å°‡é•·æ–‡å­—åˆ‡æˆå°å¡Š."""
    chunks = []
    start = 0
    while start < len(text):
        end = start + chunk_size
        chunk = text[start:end]
        chunks.append(chunk)
        start = end - overlap
    return chunks


def process_all_documents() -> List[Dict]:
    """è™•ç†æ‰€æœ‰æ–‡ä»¶ï¼Œè¿”å›æ–‡ä»¶æ¸…å–®."""
    documents = []

    # è™•ç† PDF
    pdf_dir = KNOWLEDGE_RAW / "pdf"
    if pdf_dir.exists():
        for pdf_file in pdf_dir.glob("*.pdf"):
            text = extract_text_from_pdf(pdf_file)
            if text:
                documents.append({
                    "source": str(pdf_file.name),
                    "type": "pdf",
                    "content": text,
                })

    # è™•ç†æ–‡å­—æª”
    text_dir = KNOWLEDGE_RAW / "text"
    if text_dir.exists():
        for txt_file in text_dir.glob("*.txt"):
            text = extract_text_from_txt(txt_file)
            if text:
                documents.append({
                    "source": str(txt_file.name),
                    "type": "txt",
                    "content": text,
                })

        for docx_file in text_dir.glob("*.docx"):
            text = extract_text_from_docx(docx_file)
            if text:
                documents.append({
                    "source": str(docx_file.name),
                    "type": "docx",
                    "content": text,
                })

    # è™•ç†å½±ç‰‡ï¼ˆå¦‚æœæœ‰å®‰è£ whisperï¼‰
    video_dir = KNOWLEDGE_RAW / "video"
    if video_dir.exists():
        for video_file in video_dir.glob("*"):
            if video_file.suffix.lower() in ['.mp4', '.mp3', '.wav', '.m4a', '.webm']:
                text = transcribe_video(video_file)
                if text:
                    documents.append({
                        "source": str(video_file.name),
                        "type": "video",
                        "content": text,
                    })

    return documents


def build_vector_database(documents: List[Dict]):
    """å»ºç«‹å‘é‡è³‡æ–™åº«."""
    print("\nğŸ”§ å»ºç«‹å‘é‡è³‡æ–™åº«...")

    CHROMA_DB_PATH.mkdir(parents=True, exist_ok=True)

    # ä½¿ç”¨ ChromaDB
    client = chromadb.PersistentClient(path=str(CHROMA_DB_PATH))

    # ä½¿ç”¨ OpenAI embeddingï¼ˆéœ€è¦è¨­å®š OPENAI_API_KEYï¼‰
    # æˆ–ä½¿ç”¨å…è²»çš„ sentence-transformers
    try:
        openai_ef = embedding_functions.OpenAIEmbeddingFunction(
            api_key=os.getenv("OPENAI_API_KEY"),
            model_name="text-embedding-3-small"
        )
        ef = openai_ef
    except:
        print("  âš ï¸ ç„¡æ³•ä½¿ç”¨ OpenAIï¼Œæ”¹ç”¨æœ¬åœ° embedding")
        ef = embedding_functions.DefaultEmbeddingFunction()

    # å»ºç«‹æˆ–å–å¾— collection
    collection = client.get_or_create_collection(
        name="ni_haixia_knowledge",
        embedding_function=ef,
        metadata={"description": "å€ªæµ·å»ˆçŸ¥è­˜åº«"}
    )

    # æ¸…ç©ºèˆŠè³‡æ–™
    if collection.count() > 0:
        collection.delete(where={})

    # è™•ç†æ¯å€‹æ–‡ä»¶
    all_chunks = []
    all_metadatas = []
    all_ids = []

    for doc in documents:
        chunks = chunk_text(doc["content"])
        for i, chunk in enumerate(chunks):
            all_chunks.append(chunk)
            all_metadatas.append({
                "source": doc["source"],
                "type": doc["type"],
                "chunk_index": i,
            })
            all_ids.append(f"{doc['source']}_{i}")

    # æ‰¹æ¬¡æ–°å¢
    if all_chunks:
        # ChromaDB é™åˆ¶æ¯æ¬¡æœ€å¤š 5000 ç­†
        batch_size = 500
        for i in range(0, len(all_chunks), batch_size):
            batch_chunks = all_chunks[i:i+batch_size]
            batch_metadatas = all_metadatas[i:i+batch_size]
            batch_ids = all_ids[i:i+batch_size]

            collection.add(
                documents=batch_chunks,
                metadatas=batch_metadatas,
                ids=batch_ids,
            )
            print(f"  âœ… å·²æ–°å¢ {min(i+batch_size, len(all_chunks))}/{len(all_chunks)} ç­†")

    print(f"\nâœ… å‘é‡è³‡æ–™åº«å»ºç«‹å®Œæˆï¼å…± {collection.count()} ç­†è³‡æ–™")


def save_processed_documents(documents: List[Dict]):
    """å„²å­˜è™•ç†å¾Œçš„æ–‡ä»¶ï¼ˆç´”æ–‡å­—ç‰ˆæœ¬ï¼‰."""
    KNOWLEDGE_PROCESSED.mkdir(parents=True, exist_ok=True)

    for doc in documents:
        output_file = KNOWLEDGE_PROCESSED / f"{Path(doc['source']).stem}.txt"
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(f"ä¾†æº: {doc['source']}\n")
            f.write(f"é¡å‹: {doc['type']}\n")
            f.write("=" * 50 + "\n\n")
            f.write(doc['content'])

    # å„²å­˜ç´¢å¼•
    index_file = KNOWLEDGE_PROCESSED / "index.json"
    index = [{"source": d["source"], "type": d["type"], "length": len(d["content"])} for d in documents]
    with open(index_file, 'w', encoding='utf-8') as f:
        json.dump(index, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ“ å·²å„²å­˜è™•ç†å¾Œçš„æ–‡ä»¶åˆ°: {KNOWLEDGE_PROCESSED}")


def main():
    """ä¸»ç¨‹å¼."""
    print("=== å»ºç«‹å€ªæµ·å»ˆçŸ¥è­˜åº« ===\n")

    # 1. è™•ç†æ‰€æœ‰æ–‡ä»¶
    print("ğŸ“š è™•ç†åŸå§‹æ–‡ä»¶...")
    documents = process_all_documents()

    if not documents:
        print("\nâš ï¸ æ‰¾ä¸åˆ°ä»»ä½•æ–‡ä»¶ï¼è«‹å…ˆåŸ·è¡Œ gdrive_sync.py ä¸‹è¼‰è³‡æ–™")
        return

    print(f"\næ‰¾åˆ° {len(documents)} å€‹æ–‡ä»¶")

    # 2. å„²å­˜è™•ç†å¾Œçš„æ–‡ä»¶
    save_processed_documents(documents)

    # 3. å»ºç«‹å‘é‡è³‡æ–™åº«
    build_vector_database(documents)

    print("\nğŸ‰ çŸ¥è­˜åº«å»ºç«‹å®Œæˆï¼")


if __name__ == "__main__":
    main()
